# Сравнение производительности асинхронной и блокирующей реализации

## Время обработки запроса

|          | PUT old         | PUT new        | GET old        | GET new         |
|----------|---------        |---------       |---------       |---------        |
| 50.000%  |    11.53ms      |     0.91ms     |    1.75ms      |       0.87ms    |
| 75.000%  |    20.05ms      |     1.18ms     |    2.34ms      |       1.13ms    |
| 90.000%  |    31.92ms      |     1.36ms     |    2.97ms      |       1.30ms    |
| 99.000%  |    76.54ms      |     1.55ms     |    5.36ms      |       1.51ms    |
| 99.900%  |   122.50ms      |     2.11ms     |    8.45ms      |       3.23ms    |
| 99.990%  |   162.69ms      |     8.20ms     |   12.89ms      |       7.02ms    |
| 99.999%  |   188.29ms      |    16.61ms     |   15.48ms      |       8.15ms    |
| 100.000% |   204.16ms      |    16.61ms     |   18.43ms      |       8.65ms    |
| timeout% |   3.38e-3       |       13.53    |    3.38e-3     |       7.30      |
|Requests/sec|  96481.65     |   3399.01      |  96556.28      |     6077.83     |
                                               
По таблице выше видно, что при переходе к асинхронной реализации, время ответа значительно 
сократилось, но также, значительно возросло число таймаутов. 

## Время обработки запроса при смешанной нагрузке
            
|          | status/old | status while get/old | status/new | status while get/new |
|----------|---------   |---------             |---------   |---------             |
| 50.000%  |   1.39ms   |    6.16ms            |   1.75ms   |     3.33ms           |
| 75.000%  |   1.91ms   |   11.87ms            |   2.33ms   |     5.38ms           |
| 90.000%  |   2.37ms   |   21.18ms            |   3.03ms   |     7.70ms           |
| 99.000%  |   3.32ms   |   55.52ms            |   4.88ms   |    15.19ms           |
| 99.900%  |   5.88ms   |  106.11ms            |   6.59ms   |    25.04ms           |
| 99.990%  |  11.35ms   |  228.86ms            |   9.18ms   |    31.84ms           |
| 99.999%  |  14.80ms   | 255.74ms             |  10.72ms   |    35.58ms           |
| 100.000% |  21.66ms   | 260.99ms             |  11.65ms   |    39.49ms           |
| timeout% |  3.36e-3   |   3.38e-3            |  3.40e-3   |    3.39e-3           |

По таблице выше видно, что при переходе к асинхронной реализации, время ответа на
"лёгкие" запросы, выполненые отдельно и во время "тяжёлых" запросов, отличается
в 2 раза, в то время как  при блокирующей реализации, время ответа отличается приблизительно в 5 раз.

 

# Сравнение производительности при переходе к реализации с шардированием

## Время обработки запроса

|          | PUT new         | PUT old        | GET new        | GET old         |
|----------|---------        |---------       |---------       |---------        |
| 50.000%  |    0.95ms       |     0.91ms     |    0.99ms      |       0.87ms    |
| 75.000%  |    1.21ms       |     1.18ms     |    1.25ms      |       1.13ms    |
| 90.000%  |    1.37ms       |     1.36ms     |    1.41ms      |       1.30ms    |
| 99.000%  |    1.56ms       |     1.55ms     |    2.01ms      |       1.51ms    |
| 99.900%  |    3.72ms       |     2.11ms     |    7.28ms      |       3.23ms    |
| 99.990%  |    9.09ms       |     8.20ms     |   12.41ms      |       7.02ms    |
| 99.999%  |   17.07ms       |    16.61ms     |   14.84ms      |       8.15ms    |
| 100.000% |   17.23ms       |    16.61ms     |   18.80ms      |       8.65ms    |
| timeout% |     6.41        |       13.53    |    6.80        |       7.30      |
|Requests/sec|     6910.05   |     3399.01    |    6542.54     |       6077.83   |

По таблице выше видно, что лучше не стало, но и хуже тоже не стало.
Это странно, потому что по результатм профиллирования, время похода в другую ноду
за данными, в 2 раза превышает время чтения данных с локальной ноды.
Также это странно потому, что число запускаемых потоков при переходе к кластерной реализации
стало в 3 раза больше, и теперь уже в 6 раз превышает число физических потоков
на машине, на которой проводилось тестирование. По идее, производительность должна
была снизится.  

# Сравнение производительности после добавления реплик

## Время обработки запроса

|          | PUT old         | PUT new        | GET old        | GET new         |
|----------|---------        |---------       |---------       |---------        |
| 50.000%  |    0.95ms       |      1.09ms    |    0.99ms      |      1.13ms     |
| 75.000%  |    1.21ms       |      1.33ms    |    1.25ms      |      1.37ms     |
| 90.000%  |    1.37ms       |      1.50ms    |    1.41ms      |      1.57ms     |
| 99.000%  |    1.56ms       |      1.84ms    |    2.01ms      |      1.99ms     |
| 99.900%  |    3.72ms       |      6.64ms    |    7.28ms      |      6.21ms     |
| 99.990%  |    9.09ms       |      9.34ms    |   12.41ms      |      8.85ms     |
| 99.999%  |   17.07ms       |     12.23ms    |   14.84ms      |      10.35ms    |
| 100.000% |   17.23ms       |     12.23ms    |   18.80ms      |      10.35ms    |
| timeout% |     6.41        |     18.47      |    6.80        |     19.13       |
|Requests/sec|     6910.05   |     2520.23    |    6542.54     |       2435.24   |   
 
По таблице выше видно, что время обработки запроса и число таймаутов выросли, по сравнению с предыдущей версией.
Это объясняется тем, что теперь для выполнения запроса, его должны обработать 2/3 узлов,
которые тоже, в свою очередь, находятся под нагрузкой.   

# Сравнение производительности при испольовании асинхронных запросов

## Время обработки запроса

|          | PUT new         | PUT old        | GET new        | GET old         |
|----------|---------        |---------       |---------       |---------        |
| 50.000%  | 12.15ms         |      1.09ms    |    3.58ms      |      1.13ms     |
| 75.000%  | 16.17ms         |      1.33ms    |    8.61ms      |      1.37ms     |
| 90.000%  | 19.81ms         |      1.50ms    |   13.24ms      |      1.57ms     |
| 99.000%  | 28.58ms         |      1.84ms    |   22.22ms      |      1.99ms     |
| 99.900%  | 38.05ms         |      6.64ms    |   31.22ms      |      6.21ms     |
| 99.990%  | 42.59ms         |      9.34ms    |   39.68ms      |      8.85ms     |
| 99.999%  | 44.13ms         |     12.23ms    |   46.08ms      |      10.35ms    |
| 100.000% | 44.90ms         |     12.23ms    |   47.68ms      |      10.35ms    |
| timeout% |    0.034        |     18.47      |    0.033       |      19.13      |
|Requests/sec|      9595.78  |    2520.23     |    9666.54     |      2435.24    |

По результатам видно, что время обработки запросов значительно возросло, но также
значительно снизилось число таймаутов и возросла пропускная способность.
Ухудшение времени обработки  вызвано тем, что ответ теперь формируется не сразу, после
получения ответов от других нод, а в момент, когда соответствующая задача попадёт в обработку.

## Анализ результатов профилирования

#### Блокировки 
 По результатам профилирования блокировок видно, что большая часть блокировок возникает 
 во время работы аиснхронного HTTP клиента, при взаимодействии с пулом селекторов.


# Нагрузочное тестирование танком

## `PUT` с уникальными ключами
[результаты](https://overload.yandex.net/228896)

Система стабильно работает при 8000 RPS. 

По графикам видно, что иногда происходят "всплески" по времени ответа.
Это, скорее всего, вызвано задержками в ответах от других узлов кластера,
или задержками в обработке этих ответов, 
которые могут происходить из-за нехватки вычислительных ресурсов. 

Также, на графиках видно, что после возвращения системы к стабильному режиму работы,
среднее время ответа возросло. 
Это может быть вызвано тем, что очереди обработки запросов не успевают вычищаться,
и каждый входящий запрос поступает в обработку не моментально, а с задержкой. 

## `PUT` с частичной перезаписью
[результаты](https://overload.yandex.net/228871)

Ситуация аналогична предыдущей, за исключением того, что среднее время ответа 
ниже в 2 раза (что странно).

## `GET`  с равномерным распределением
[результаты](https://overload.yandex.net/228925)

Ситуация аналогична первой. 

По графикам можно заметить, что система начинает "нормально" отвечать
с небольшой задержкой, после возвращения нагрузки до стабильных пределов.
Это объясняется тем, что некоторое время система досчитывает ответы на запросы, которые
поступили во время большой нагрузки.

## `GET`  со смещением распределения к новым
[результаты](https://overload.yandex.net/228927)

Ситуация аналогична предыдущей, за исключением того, что среднее время ответа 
ниже в 10 раз. В данном случае это не странно, т.к. ожидается, что свежие записи
ещё не упали на диск и доступ к ним значительно быстрее.

## Смешанная нагрузка
[результаты](https://overload.yandex.net/228935)

Ситуация аналогична первой. 

Пографикам можно заметить, что время ответа для 'PUT' и 'GET' запросов
приблизительно совпадает.

## Range запросы

Тестирование проводилось на запросах фиксированного размера (1000 записей),
который подобран так, чтобы время передачи ответа по сети не перекрывало время работы системы. 

[результаты](https://overload.yandex.net/228944)

По результатам видно, что задержка овтета меньше 1ms, что и ожидалось.
Данные для ответа формируются по мере получения данных клиентом, и время их обработки
влияют не на задержку, а на время получения ответа (`receive_time`).

"Всплески" по времени ответа можно объяснить также, как и в первом случае.
